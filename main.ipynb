{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Watch for any changes in vocabulary.py, data_loader.py, utils.py or model.py, and re-load it automatically.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from pycocotools.coco import COCO\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from utils import train, validate, save_epoch, early_stopping\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.91s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1415/414113 [00:00<01:00, 6863.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:01<00:00, 6720.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/202654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202654/202654 [00:28<00:00, 7061.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set values for the training variables\n",
    "batch_size = 32         # batch size\n",
    "vocab_threshold = 5     # minimum word count threshold\n",
    "vocab_from_file = True  # if True, load existing vocab file\n",
    "embed_size = 256        # dimensionality of image and word embeddings\n",
    "hidden_size = 512       # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 10          # number of training epochs\n",
    "\n",
    "# Define a transform to pre-process the training images\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Define a transform to pre-process the validation images\n",
    "transform_val = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.CenterCrop(224),                      # get 224x224 crop from the center\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader, applying the transforms\n",
    "train_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "val_loader = get_loader(transform=transform_val,\n",
    "                         mode='val',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "\n",
    "# The size of the vocabulary\n",
    "vocab_size = len(train_loader.dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps: 12942\n",
      "Number of validation steps: 6333\n"
     ]
    }
   ],
   "source": [
    "# Initialize the encoder and decoder\n",
    "encoder = EncoderCNN(embed_size, architecture='resnet50')\n",
    "# encoder = EncoderCNN(embed_size, architecture='densenet161')\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    \n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify the learnable parameters of the model\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(params=params, lr=0.001)\n",
    "\n",
    "# Set the total number of training and validation steps per epoch\n",
    "total_train_step = math.ceil(len(train_loader.dataset.caption_lengths) / train_loader.batch_sampler.batch_size)\n",
    "total_val_step = math.ceil(len(val_loader.dataset.caption_lengths) / val_loader.batch_sampler.batch_size)\n",
    "print (\"Number of training steps:\", total_train_step)\n",
    "print (\"Number of validation steps:\", total_val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train step [3/12942], 38s, Loss: 8.6009, Perplexity: 5436.6264"
     ]
    }
   ],
   "source": [
    "# Keep track of train and validation losses and validation Bleu-4 scores by epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_bleus = []\n",
    "# Keep track of the current best validation Bleu score\n",
    "best_val_bleu = float(\"-INF\")\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(train_loader, encoder, decoder, criterion, optimizer, \n",
    "                       vocab_size, epoch, total_train_step)\n",
    "    train_losses.append(train_loss)\n",
    "    val_loss, val_bleu = validate(val_loader, encoder, decoder, criterion,\n",
    "                                  train_loader.dataset.vocab, epoch, total_val_step)\n",
    "    val_losses.append(val_loss)\n",
    "    val_bleus.append(val_bleu)\n",
    "    if val_bleu > best_val_bleu:\n",
    "        print (\"Validation Bleu-4 improved from {:0.4f} to {:0.4f}, saving model to best-model.pkl\".\n",
    "               format(best_val_bleu, val_bleu))\n",
    "        best_val_bleu = val_bleu\n",
    "        filename = os.path.join(\"./models\", \"best-model.pkl\")\n",
    "        save_epoch(filename, encoder, decoder, optimizer, train_losses, val_losses, \n",
    "                   val_bleu, val_bleus, epoch)\n",
    "    else:\n",
    "        print (\"Validation Bleu-4 did not improve, saving model to model-{}.pkl\".format(epoch))\n",
    "    # Save the entire model anyway, regardless of being the best model so far or not\n",
    "    filename = os.path.join(\"./models\", \"model-{}.pkl\".format(epoch))\n",
    "    save_epoch(filename, encoder, decoder, optimizer, train_losses, val_losses, \n",
    "               val_bleu, val_bleus, epoch)\n",
    "    print (\"Epoch [%d/%d] took %ds\" % (epoch, num_epochs, time.time() - start_time))\n",
    "    if epoch > 5:\n",
    "        # Stop if the validation Bleu doesn't improve for 3 epochs\n",
    "        if early_stopping(val_bleus, 3):\n",
    "            break\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
